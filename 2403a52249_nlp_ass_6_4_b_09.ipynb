{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrIpAngqXXCT+sI0NhkkCv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhavana0716/NLP-lab/blob/main/2403a52249_nlp_ass_6_4_b_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load text data"
      ],
      "metadata": {
        "id": "ycW5kNADFPSe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GC7YcnBxBIJV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data=pd.read_excel('/content/LDA-Data.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLVtwGrQCyDk",
        "outputId": "80f7f770-f97d-4407-8b8b-c189b7bae299"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             News\n",
            "0   Virat scored century in match\n",
            "1            BJP won in elections\n",
            "2  Bumra took 5 wicket in a match\n",
            "3  Congress form state government\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Preprocesing: Clean Text, Word Tokenization, stopword removal, lemma,Rejoin"
      ],
      "metadata": {
        "id": "DarmfZSrFH1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def nltk_preprocessing_pipeline(text):\n",
        "    # Initialize NLTK tools\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # 1. Preprocess text (from previous steps)\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    # Remove mentions\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    # Remove hashtags\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "\n",
        "    # Remove emojis\n",
        "    emoji_pattern = re.compile(\n",
        "        \"[\"\n",
        "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        \"\\U00002702-\\U000027B0\"\n",
        "        \"\\U000024C2-\\U0001F251\"\n",
        "        \"]+\", flags=re.UNICODE\n",
        "       )\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "\n",
        "    # 2. Word Tokenization\n",
        "    tokenized_words = word_tokenize(text)\n",
        "\n",
        "    # 3. Stopword Removal\n",
        "    filtered_words = [word for word in tokenized_words if word not in stop_words]\n",
        "\n",
        "    # 4. Lemmatization\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "\n",
        "    # 5. Rejoin words\n",
        "    clean_summary = ' '.join(lemmatized_words)\n",
        "\n",
        "    return clean_summary\n",
        "\n",
        "print(\"NLTK preprocessing pipeline function created successfully!\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r_iF8xJDP5B",
        "outputId": "234d6a70-360d-409f-b1c6-941f827f14f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK preprocessing pipeline function created successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BoW"
      ],
      "metadata": {
        "id": "P4ZqJpK7Falw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['clean_News'] = data['News'].apply(nltk_preprocessing_pipeline)\n",
        "print(\"\\nComparison of previous clean_summaries and new clean_summaries_pipeline (first 5 rows):\")\n",
        "print(data[['clean_News']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSvPDN86Dn23",
        "outputId": "ba9c6c29-1952-4775-aab8-f3ab412e876e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison of previous clean_summaries and new clean_summaries_pipeline (first 5 rows):\n",
            "                       clean_News\n",
            "0      virat scored century match\n",
            "1                    bjp election\n",
            "2       bumra took 5 wicket match\n",
            "3  congress form state government\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BoW as frame"
      ],
      "metadata": {
        "id": "30qcFg6dFdjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Vectorize the cleaned summaries\n",
        "count_vectorizer = CountVectorizer(max_df=0.95, min_df=1, stop_words='english')\n",
        "doc_term_matrix = count_vectorizer.fit_transform(data['clean_News'])"
      ],
      "metadata": {
        "id": "hZi_VI4ZD2LX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Get feature (word) names\n",
        "feature_names = count_vectorizer.get_feature_names_out()\n",
        "# Convert sparse matrix to DataFrame\n",
        "bow_df = pd.DataFrame(doc_term_matrix.toarray(),columns=feature_names)\n",
        "# Display BoW matrix for top 10 documents\n",
        "bow_top_10 = bow_df.head(10)\n",
        "print(bow_top_10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_K5qlWlUD4Q6",
        "outputId": "3da56e2e-dcfc-42c4-c153-f0780afa7ebc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   bjp  bumra  century  congress  election  form  government  match  scored  \\\n",
            "0    0      0        1         0         0     0           0      1       1   \n",
            "1    1      0        0         0         1     0           0      0       0   \n",
            "2    0      1        0         0         0     0           0      1       0   \n",
            "3    0      0        0         1         0     1           1      0       0   \n",
            "\n",
            "   state  took  virat  wicket  \n",
            "0      0     0      1       0  \n",
            "1      0     0      0       0  \n",
            "2      0     1      0       1  \n",
            "3      1     0      0       0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply LDA"
      ],
      "metadata": {
        "id": "PXHh0xAwFjS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# Initialize and fit LDA model\n",
        "num_topics = 2\n",
        "LDA = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
        "LDA.fit(doc_term_matrix)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "c_cJ88k_EGhT",
        "outputId": "96d983eb-bc32-467f-d126-225716de4e74"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(n_components=2, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=2, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LatentDirichletAllocation</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\">?<span>Documentation for LatentDirichletAllocation</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LatentDirichletAllocation(n_components=2, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identify words for  each topic"
      ],
      "metadata": {
        "id": "EaBUlBQ0FpbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_topics(model, feature_names, num_top_words):\n",
        "    for topic_idx in range(len(model.components_)):\n",
        "        print(f\"\\nTopic {topic_idx}:\")\n",
        "\n",
        "        # Get word weights for this topic\n",
        "        topic_weights = model.components_[topic_idx]\n",
        "\n",
        "        # Get indices of words sorted by weight (descending)\n",
        "        sorted_indices = topic_weights.argsort()[::-1]\n",
        "\n",
        "        # Take top N words\n",
        "        top_indices = sorted_indices[:num_top_words]\n",
        "\n",
        "        # Print top words\n",
        "        for idx in top_indices:\n",
        "            print(feature_names[idx], end=\" \")\n",
        "        print()"
      ],
      "metadata": {
        "id": "FxMHV9CEEU85"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topic modeling"
      ],
      "metadata": {
        "id": "1tPDArodFwxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display top words for each topic\n",
        "num_top_words = 10\n",
        "print(f\"\\nTop {num_top_words} words per topic:\")\n",
        "display_topics(LDA, count_vectorizer.get_feature_names_out(), num_top_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHkVhC3oEa56",
        "outputId": "87f9d786-4c45-4fcb-d7bf-abd8c23a6a6d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 words per topic:\n",
            "\n",
            "Topic 0:\n",
            "form government congress state election bjp match wicket bumra took \n",
            "\n",
            "Topic 1:\n",
            "match virat century scored took bumra wicket bjp election state \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign topics to each document\n",
        "document_topics = LDA.transform(doc_term_matrix)\n",
        "data['topic'] = document_topics.argmax(axis=1)\n",
        "\n",
        "print(\"\\nDataFrame with assigned topics (first 5 rows):\")\n",
        "print(data[['clean_News', 'topic']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS_RABeiEe9a",
        "outputId": "fd01bfe8-f895-40bf-e595-65e11e192d48"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame with assigned topics (first 5 rows):\n",
            "                       clean_News  topic\n",
            "0      virat scored century match      1\n",
            "1                    bjp election      0\n",
            "2       bumra took 5 wicket match      1\n",
            "3  congress form state government      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task #2 : Research paper Data**"
      ],
      "metadata": {
        "id": "dn20ZIkwF4TL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load  Text Data"
      ],
      "metadata": {
        "id": "4n2WcQRcK4XC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "\n",
        "# Path to the zip file\n",
        "zip_file_path = '/content/nlp-arxiv paper absract.zip'\n",
        "# Name of the CSV file inside the zip archive\n",
        "csv_file_in_zip = 'arxiv_data.csv'\n",
        "\n",
        "# Open the zip file and read the CSV\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zf:\n",
        "    with zf.open(csv_file_in_zip) as f:\n",
        "        df = pd.read_csv(f)"
      ],
      "metadata": {
        "id": "HlK_HkZBGojf"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyAQglgoHAf2",
        "outputId": "a6e53d99-a916-4b92-8123-80cf1dfff6f3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              titles  \\\n",
            "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
            "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
            "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
            "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
            "4  Background-Foreground Segmentation for Interio...   \n",
            "\n",
            "                                           summaries  \\\n",
            "0  Stereo matching is one of the widely used tech...   \n",
            "1  The recent advancements in artificial intellig...   \n",
            "2  In this paper, we proposed a novel mutual cons...   \n",
            "3  Consistency training has proven to be an advan...   \n",
            "4  To ensure safety in automated driving, the cor...   \n",
            "\n",
            "                         terms  \n",
            "0           ['cs.CV', 'cs.LG']  \n",
            "1  ['cs.CV', 'cs.AI', 'cs.LG']  \n",
            "2           ['cs.CV', 'cs.AI']  \n",
            "3                    ['cs.CV']  \n",
            "4           ['cs.CV', 'cs.LG']  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Preprocesing: Clean Text, Word Tokenization, stopword removal, lemma,Rejoin"
      ],
      "metadata": {
        "id": "Mqp6RgdbK7t-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def nltk_preprocessing_pipeline(text):\n",
        "    # Initialize NLTK tools\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # 1. Preprocess text (from previous steps)\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    # Remove mentions\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    # Remove hashtags\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "# Remove emojis\n",
        "    emoji_pattern = re.compile(\n",
        "        \"[\"\n",
        "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        \"\\U00002702-\\U000027B0\"\n",
        "        \"\\U000024C2-\\U0001F251\"\n",
        "        \"]+\", flags=re.UNICODE\n",
        "    )\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "\n",
        "    # 2. Word Tokenization\n",
        "    tokenized_words = word_tokenize(text)\n",
        "\n",
        "    # 3. Stopword Removal\n",
        "    filtered_words = [word for word in tokenized_words if word not in stop_words]\n",
        "\n",
        "    # 4. Lemmatization\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "\n",
        "    # 5. Rejoin words\n",
        "    clean_summary = ' '.join(lemmatized_words)\n",
        "\n",
        "    return clean_summary\n",
        "\n",
        "print(\"NLTK preprocessing pipeline function created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8ZvoXEuHjkC",
        "outputId": "b2567fa0-b755-4c86-9752-2174a391970e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK preprocessing pipeline function created successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BoW"
      ],
      "metadata": {
        "id": "_0mQzC7qLLa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_summaries_pipeline'] = df['summaries'].apply(nltk_preprocessing_pipeline)\n",
        "print(\"\\nComparison of previous clean_summaries and new clean_summaries_pipeline (first 5 rows):\")\n",
        "print(df[['clean_summaries_pipeline']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj_t0gn1H4BF",
        "outputId": "41e9b58a-6637-4f55-ea38-b426691b5c91"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison of previous clean_summaries and new clean_summaries_pipeline (first 5 rows):\n",
            "                            clean_summaries_pipeline\n",
            "0  stereo matching one widely used technique infe...\n",
            "1  recent advancement artificial intelligence ai ...\n",
            "2  paper proposed novel mutual consistency networ...\n",
            "3  consistency training proven advanced semisuper...\n",
            "4  ensure safety automated driving correct percep...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BoW as Dataframe"
      ],
      "metadata": {
        "id": "oaiYx2CqLNJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Vectorize the cleaned summaries\n",
        "count_vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
        "doc_term_matrix = count_vectorizer.fit_transform(df['clean_summaries_pipeline'])"
      ],
      "metadata": {
        "id": "dTk-1uXuIjXw"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Get feature (word) names\n",
        "feature_names = count_vectorizer.get_feature_names_out()\n",
        "# Convert sparse matrix to DataFrame\n",
        "bow_df = pd.DataFrame(doc_term_matrix.toarray(),columns=feature_names)\n",
        "# Display BoW matrix for top 10 documents\n",
        "bow_top_10 = bow_df.head(10)\n",
        "print(bow_top_10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JstZfqlIobb",
        "outputId": "a0202009-9e46-4399-ebd4-adfd28ba9280"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   00  000  00001  00002  00005  0001  00010  0002  0003  0004  ...  zslkg  \\\n",
            "0   0    0      0      0      0     0      0     0     0     0  ...      0   \n",
            "1   0    0      0      0      0     0      0     0     0     0  ...      0   \n",
            "2   0    0      0      0      0     0      0     0     0     0  ...      0   \n",
            "3   0    0      0      0      0     0      0     0     0     0  ...      0   \n",
            "4   0    0      0      0      0     0      0     0     0     0  ...      0   \n",
            "5   0    0      0      0      0     0      0     0     0     0  ...      0   \n",
            "6   0    0      0      0      0     0      0     0     0     0  ...      0   \n",
            "7   0    0      0      0      0     0      0     0     0     0  ...      0   \n",
            "8   0    0      0      0      0     0      0     0     0     0  ...      0   \n",
            "9   0    0      0      0      0     0      0     0     0     0  ...      0   \n",
            "\n",
            "   zspu  zssbir  zsslr  zssr  zurich  zvos  zynq  zynq7000  zynqnet  \n",
            "0     0       0      0     0       0     0     0         0        0  \n",
            "1     0       0      0     0       0     0     0         0        0  \n",
            "2     0       0      0     0       0     0     0         0        0  \n",
            "3     0       0      0     0       0     0     0         0        0  \n",
            "4     0       0      0     0       0     0     0         0        0  \n",
            "5     0       0      0     0       0     0     0         0        0  \n",
            "6     0       0      0     0       0     0     0         0        0  \n",
            "7     0       0      0     0       0     0     0         0        0  \n",
            "8     0       0      0     0       0     0     0         0        0  \n",
            "9     0       0      0     0       0     0     0         0        0  \n",
            "\n",
            "[10 rows x 47626 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply LDA"
      ],
      "metadata": {
        "id": "UictdgVFLWBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# Initialize and fit LDA model\n",
        "num_topics = 2\n",
        "LDA = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
        "LDA.fit(doc_term_matrix)"
      ],
      "metadata": {
        "id": "Gguyo5w0NlQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Identify words for  each topic"
      ],
      "metadata": {
        "id": "5tZXpi7uLXW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_topics(model, feature_names, num_top_words):\n",
        "    for topic_idx in range(len(model.components_)):\n",
        "        print(f\"\\nTopic {topic_idx}:\")\n",
        "\n",
        "        # Get word weights for this topic\n",
        "        topic_weights = model.components_[topic_idx]\n",
        "\n",
        "        # Get indices of words sorted by weight (descending)\n",
        "        sorted_indices = topic_weights.argsort()[::-1]\n",
        "\n",
        "        # Take top N words\n",
        "        top_indices = sorted_indices[:num_top_words]\n",
        "\n",
        "        # Print top words\n",
        "        for idx in top_indices:\n",
        "            print(feature_names[idx], end=\" \")\n",
        "        print()"
      ],
      "metadata": {
        "id": "s2CzRpBoI2Gr"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display top words for each topic\n",
        "num_top_words = 10\n",
        "print(f\"\\nTop {num_top_words} words per topic:\")\n",
        "display_topics(LDA, count_vectorizer.get_feature_names_out(), num_top_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wimhdSs4JSrs",
        "outputId": "2aca2b79-207e-4cef-fb58-7881275efbc3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 words per topic:\n",
            "\n",
            "Topic 0:\n",
            "learning method image model network proposed feature data task propose \n",
            "\n",
            "Topic 1:\n",
            "model image method network learning data task approach feature graph \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign topics to each document\n",
        "document_topics = LDA.transform(doc_term_matrix)\n",
        "df['topic'] = document_topics.argmax(axis=1)\n",
        "\n",
        "print(\"\\nDataFrame with assigned topics (first 5 rows):\")\n",
        "print(df[['clean_summaries_pipeline', 'topic']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYQr3RQhJW-p",
        "outputId": "74301aec-719a-417d-f9a7-6bd932269c49"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame with assigned topics (first 5 rows):\n",
            "                            clean_summaries_pipeline  topic\n",
            "0  stereo matching one widely used technique infe...      1\n",
            "1  recent advancement artificial intelligence ai ...      1\n",
            "2  paper proposed novel mutual consistency networ...      1\n",
            "3  consistency training proven advanced semisuper...      1\n",
            "4  ensure safety automated driving correct percep...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Topic modeling"
      ],
      "metadata": {
        "id": "T_Wtpe-1Lmi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import NMF\n",
        "\n",
        "# Initialize NMF model\n",
        "num_topics = 2\n",
        "nmf_model = NMF(n_components=num_topics, random_state=42)\n",
        "\n",
        "# Fit the NMF model to the document-term matrix\n",
        "nmf_model.fit(doc_term_matrix)\n",
        "print(\"NMF model initialized and fitted successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH4oOKb5JdIg",
        "outputId": "176ebe66-578c-4cf9-de49-6b166c9c56da"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMF model initialized and fitted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_top_words = 10\n",
        "print(f\"\\nTop {num_top_words} words per topic (NMF):\")\n",
        "display_topics(nmf_model, count_vectorizer.get_feature_names_out(), num_top_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGCeSbsJKD9K",
        "outputId": "36c4dbb0-1b8b-4eb6-de8f-be12f69a986a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 words per topic (NMF):\n",
            "\n",
            "Topic 0:\n",
            "model learning data network method graph task approach representation feature \n",
            "\n",
            "Topic 1:\n",
            "image method object network segmentation feature detection proposed result propose \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign topics to each document\n",
        "document_topics = nmf_model.transform(doc_term_matrix)\n",
        "df['topic'] = document_topics.argmax(axis=1)\n",
        "\n",
        "print(\"\\nDataFrame with assigned topics (first 5 rows):\")\n",
        "print(df[['clean_summaries_pipeline', 'topic']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgfDpsVhKIpq",
        "outputId": "9f31cc10-a158-4b5a-d054-1bb158547f80"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame with assigned topics (first 5 rows):\n",
            "                            clean_summaries_pipeline  topic\n",
            "0  stereo matching one widely used technique infe...      1\n",
            "1  recent advancement artificial intelligence ai ...      1\n",
            "2  paper proposed novel mutual consistency networ...      0\n",
            "3  consistency training proven advanced semisuper...      0\n",
            "4  ensure safety automated driving correct percep...      0\n"
          ]
        }
      ]
    }
  ]
}